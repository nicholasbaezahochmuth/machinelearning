{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.537992\n",
      "n_neighbors: 3, average score: 0.703410\n",
      "n_neighbors: 5, average score: 0.758277\n",
      "n_neighbors: 10, average score: 0.725944\n",
      "n_neighbors: 20, average score: 0.621668\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters can be used to adjust the fit of a ml-model\n",
    "# \"hyperparameter tuning\" is done using a brute force search, for example \n",
    "# over multiple values of n_neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# generate a toy dataset\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle = True)\n",
    "\n",
    "# for each parameter setting do cross-validation\n",
    "for n_neighbors in [1,3,5,10,20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print \"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb4bc748>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaeda828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# there is a function called validation_plot which plots one parameter such as number of \n",
    "# neighbors against training and validation error (using cross-validation)\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1,3,5,10,20,50]\n",
    "train_errors, test_errors = validation_curve(KNeighborsRegressor(), X, y, \n",
    "                                             param_name='n_neighbors',\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label='train errors')\n",
    "plt.plot(n_neighbors, test_errors.mean(axis=1), label='test errors')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.022086\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.055777\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.005297\n",
      "C: 0.001000, gamma: 1.000000, average score: 0.008344\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.001671\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.019553\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.091870\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.086761\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.004807\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.056073\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.489771\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.475714\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.120324\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.560419\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.667593\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.673781\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.564951\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.605981\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.663850\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.732305\n"
     ]
    }
   ],
   "source": [
    "# if multiple parameters are important such as C and gamma in SVR, all possible\n",
    "# combinations are tried\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do a cross-validation\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print \"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as this practice is common, there is a class in scikit-learn for this purpose, GridSearchCV\n",
    "# GridSearchCV takes a dictionary that describes parameters that should be tried and \n",
    "# a model to train\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.054897, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.009546, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.000587, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.051755, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.007532, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .............. C=0.001, gamma=0.01, score=0.001280, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.038155, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.001221, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.009468, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.040464, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.000436, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.008156, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.051431, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.007325, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .............. C=0.01, gamma=0.001, score=0.001470, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.021424, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.011906, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.019921, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.087206, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.086631, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.096339, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.080279, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.076592, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.084041, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.018391, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.013843, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.021773, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.173053, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.174889, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.180053, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.600130, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.490447, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.488746, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.585698, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.471189, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.457268, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.181126, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.188950, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.195355, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.640734, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.546314, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.579647, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.658679, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.671066, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.690881, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.708772, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.714583, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.740725, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.629585, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.559223, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.596528, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.662731, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.626812, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.645938, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.598295, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.679831, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.696045, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.734922, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.787244, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.771767, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One great thing about GridSearchCV is that it is a meta-estimator. It takes an estimator \n",
    "# like SVR and creates a new estimator, that behaves exactly the same - in this case\n",
    "# like a regressor. And so we can call fit on it to train it:\n",
    "\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use predict() or score() such as in all models\n",
    "\n",
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764347080919\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a problem with using the grid score for evaluation. You might be making a \n",
    "# multiple hypothesis testing error.\n",
    "# If very many parameter settings are tried, some will work better than others just by chance\n",
    "# and the score that was obtained might not reflect how the model would perform on new\n",
    "# unseen data.\n",
    "\n",
    "# Therefore it is good to split off a seperate test-set before performing grid-search\n",
    "\n",
    "# We do this by using train_test_split(). Training GridSearchCV() on the training set, and \n",
    "# applying the score method to the test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.003754, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.001623, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.007980, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.006677, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.001414, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.020541, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.112187, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.100813, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.022732, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.200325, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.560395, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.532042, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.217197, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.644048, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.734117, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.742405, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.635589, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.665534, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.747417, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.716964, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64149052352998392"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some practitioners go for splitting data into only three parts: training, validation,\n",
    "# and testing. This is a possible alternative if the dataset is very large.\n",
    "# This can be done with scikit-learn by splitting a test-set and then applying GridSearchCV()\n",
    "# with ShuffleSplit cross-validation with a single iteration\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method is much faster but might result in worse hyperparameters and worse results\n",
    "\n",
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
